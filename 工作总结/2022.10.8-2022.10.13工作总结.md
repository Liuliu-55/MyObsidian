# 2022.10.8-2022.10.13工作总结

## 网络结构

### 1.雷达点云

**将雷达点云作为搜索，将相同世界坐标系中的相机特征与雷达RD图进行融合**

#### 点云选取策略

* 取反射power最大

```python
re1 = list(map(radar_pcl[:,3].tolist().index, heapq.nlargest(50, radar_pcl[:,3].tolist())))
```

* 按雷达速度概率分布取点

```python
k = 50
pcl_unique_idx,num=np.unique(radar_pcl[:,4],return_counts=True)
numsoft = num / np.sum(num)
pcl_label_dict = {}
re1 = np.array([])
pcl_label_dicts = np.array([])
for i,ids in enumerate(pcl_unique_idx):
    sample_ids = np.where(radar_pcl[:,4]==ids)
    pcl_label_dict[ids]=sample_ids[0]
    pcl_label_dicts = np.concatenate((pcl_label_dicts,pcl_label_dict[ids].astype(int)))
            
    re=np.random.choice(pcl_label_dict[ids],int(numsoft[i]*k)).astype(int)
    re1 = np.concatenate((re,re1))
if len(re1)<k:
    re1 = np.concatenate((re1,np.random.choice(np.setdiff1d(pcl_label_dicts,re1),k-len(re1)))).astype(int)
```



#### 融合策略

#####  采取注意力机制

```python
class Transformer_Fusion(nn.Module):
    "radar_RA and Image features fusion with transformer"
    def __init__(self,in_dim):
        super(Transformer_Fusion,self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1024, out_channels= 224, kernel_size=1)
        self.conv2 = nn.Conv2d(in_channels=896, out_channels= 224, kernel_size=1)

        self.activation = activation
        self.in_dim = in_dim
        
         self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)
         self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)
         self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)
         self.gamma = nn.Parameter(torch.zeros(1))

         self.softmax  = nn.Softmax(dim=-1)      
    
    def forward(self,image_k,RD_k):
        """
            inputs :
                x : input feature maps( B X C X W X H)
            returns :
                out : self attention value + input feature 
                attention: B X N X N (N is Width*Height)
        """
        image_k = self.conv1(image_k.permute(0,3,1,2))
        RD_k = self.conv2(RD_k.permute(0,3,1,2))
        m_batchsize,C,width ,height = image_k.size()
        m_batchsize_RD,_,width_RD ,height_RD = RD_k.size()

        proj_query  = self.query_conv(RD_k).view(m_batchsize_RD,-1,width_RD*height_RD).permute(0,2,1) # B X N*C
        proj_key =  self.key_conv(image_k).view(m_batchsize,-1,width*height) # B X C x N(*W*H)
        energy =  torch.bmm(proj_query,proj_key) # transpose check  B*N*N
        attention = self.softmax(energy) # BX (N) X (N) 
        proj_value = self.value_conv(RD_k).view(m_batchsize_RD,-1,width_RD*height_RD) # B X C X N

        out = torch.bmm(proj_value,attention.permute(0,2,1) )
        out = out.view(m_batchsize,C,width,height)
        
        out = (self.gamma*out + image_k).permute(0,2,3,1)
        return out,attention
```



##### 将雷达与相机特征concat

```python
def SelectFeature(image_features, pcl, RD_features):
    # Image_features {batchx64x240x135, batchx64x240x135, batchx128x120x68, batchx256x60x34, batchx512x30x17}
    # RD_features    {batchx192x512x256, batchx128x256x128, batchx160x128x64, batchx192x64x32, batchx224x32x16}
    pcl = pcl.unsqueeze(1)
    # k = pcl.size()[2]
    image_k_feature = {}
    image_k_features = []
    RD_k_feature = {}
    RD_k_features = []

    
    for i in torch.arange(len(image_features)):
        image_features["x%d"%i]=F.pad(image_features["x%d"%i],[0, 0, 1, 1])
        image_k_feature["x%d"%i] = [[image_features["x%d"%i][b,:,(pcl[:,0,k][b,-2]/(2**(i+2))).type(torch.int):(pcl[:,0,k][b,-2]/(2**(i+2))).type(torch.int)+3,:]for k in torch.arange(pcl.size()[2])] for b in torch.arange(image_features["x%d"%i].size()[0])]
        image_k_features.append(torch.stack([torch.stack(image_k_feature["x%d"%i][j],dim=0) for j in torch.arange(len(image_k_feature["x%d"%i]))],dim=0).permute(0,2,1,3,4))
        
        RD_k_feature["x%d"%i] = [[RD_features["x%d"%i][b,:,(pcl[:,0,k][b,0]/(2**(i))).type(torch.int),(pcl[:,0,k][b,1]/(2**(i))).type(torch.int)] for k in torch.arange(pcl.size()[2])] for b in torch.arange(RD_features["x%d"%i].size()[0])]
        RD_k_features.append(torch.stack([torch.stack(RD_k_feature["x%d"%i][j],dim=0) for j in torch.arange(len(RD_k_feature["x%d"%i]))],dim=0))

    image_k = image_k_features[4].detach().reshape(-1,512,150,17)
    RD_k = RD_k_features[4].detach()



class Transformer_Fusion(nn.Module):
    "radar_RA and Image features fusion"
    def __init__(self,in_dim):
        super(Transformer_Fusion,self).__init__()
        self.conv1 = nn.Conv2d(in_channels=512, out_channels= 128, kernel_size=3,stride=(3,1))
        self.conv2 = nn.Conv2d(in_channels=128, out_channels= 1, kernel_size=1)
        self.bn1 = nn.BatchNorm2d(128)
        self.bn2 = nn.BatchNorm2d(1)
        self.relu1 = nn.ReLU(inplace=True)
        self.relu2 = nn.ReLU(inplace=True)

        self.conv3 = nn.Conv2d(in_channels=239, out_channels= 224, kernel_size=1)
        self.bn3 = nn.BatchNorm2d(224)
        self.relu3 = nn.ReLU(inplace=True)

        
    
    def forward(self,image_k,RD_k):
        image_k = self.conv1(image_k)
        image_k = self.bn1(image_k)
        image_k = self.relu1(image_k)
        image_k = self.conv2(image_k)
        image_k = self.bn2(image_k)
        image_k = self.relu2(image_k).squeeze(1)
        feature = torch.cat((RD_k,image_k),dim=2)
        feature = self.conv3(feature.permute(0,2,1).unsqueeze(3))
        feature = self.bn3(feature)
        feature = self.relu3(feature).squeeze(3).permute(0,2,1)
        # batchx1x20x224
        # RD_k = self.conv2(RD_k.permute(0,3,1,2))
        # RD_k = self.bn2(RD_k).permute(0,2,3,1)
        # RD_k = self.relu2(RD_k)
        # # batchx1x20x224
        # feature = torch.cat((RD_k,image_k),dim=3)
        # feature = self.conv3(feature.permute(0,3,1,2))
        # feature = self.bn3(feature)
        # feature = self.relu3(feature).permute(0,2,3,1)

        return feature
```



### 2.直接融合

**将图像特征与雷达RD特征图直接进行concat**

```python
class Fusion(nn.Module):
    def __init__(self):
        super(Fusion,self).__init__()
        self.conv1 = nn.Conv2d(in_channels=17, out_channels=64, kernel_size=(3,7), padding=2, stride=(1,6))
        self.bn1 = nn.BatchNorm2d(64)
        self.relu1 = nn.ReLU(inplace = True)

        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,5), padding=1, stride=(1,5))
        self.bn2 = nn.BatchNorm2d(128)
        self.relu2 = nn.ReLU(inplace = True)
        self.maxpooling = nn.MaxPool2d(kernel_size=(1,2), stride=1)

        self.conv3 = nn.Conv2d(in_channels=352, out_channels=224, kernel_size=1)
        self.bn3 = nn.BatchNorm2d(224)
        self.relu3 = nn.ReLU(inplace = True)

    def forward(self,image_features, RD_features):
        image_feature = image_features["x4"].detach().permute(0,3,2,1)
        #batchx17x30x512
        RD_feature = RD_features["x4"].detach()
        #batchx224x32x17

        image_feature = self.conv1(image_feature)
        image_feature = self.bn1(image_feature)
        image_feature = self.relu1(image_feature)
        image_feature = self.conv2(image_feature)
        image_feature = self.bn2(image_feature)
        image_feature = self.relu2(image_feature)
        image_feature = self.maxpooling(image_feature)

        feature = torch.cat([RD_feature,image_feature],dim=1)
        feature = self.conv3(feature)
        feature = self.bn3(feature)
        feature = self.relu3(feature)

        RD_features["x4"] = feature



        return RD_features

```



## 训练结果

训练数据每隔50采样，测试数据每隔20采样

### 1.雷达点云

| 图像特征                                                     | 雷达RD特征                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="E:\MyObsidian\image\individualImage (1).png" alt="individualImage (1)" style="zoom: 67%;" /> | <img src="E:\MyObsidian\image\individualImage (2).png" alt="individualImage (2)" style="zoom: 50%;" /> |

**RA特征：**

![individualImage](E:\MyObsidian\image\individualImage.png)

| 雷达点云/融合方式 | 注意力机制 | 特征concat |
| ----------------- | ---------- | ---------- |
| 最大值取样        |            |            |
| 速度概率取样      |            |            |

**MAP均低于35%，MAR均低于15%**

无论采取哪种方式，均出现多检，猜测与雷达点云进行搜索有关

### 2. 直接融合

去除雷达点云搜索，直接将雷达RD特征图与图像特征图进行融合

<img src="E:\RADIal\FFTRadNet\output\FFTRadNet_RA_192_56___Oct-14-2022___09-47-01\result\FFTRadNet_154.jpg" alt="FFTRadNet_154" style="zoom:50%;" />

<img src="E:\RADIal\FFTRadNet\output\FFTRadNet_RA_192_56___Oct-14-2022___09-47-01\result\FFTRadNet_188.jpg" alt="FFTRadNet_188" style="zoom:50%;" />



多检的情况依旧比较严重
